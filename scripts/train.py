import argparse
import os
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from models import build_cnn_scratch, build_transfer_model
from scipy.io import loadmat

# --- Args ---
parser = argparse.ArgumentParser()
parser.add_argument('--model', choices=['scratch', 'transfer'], required=True)
# parser.add_argument('--custom_aug', action='store_true')
parser.add_argument('--batch_size', type=int, default=32)
parser.add_argument('--epochs', type=int, default=10)
parser.add_argument('--custom_aug')
parser.add_argument('--img_size', type=int, default=224)
parser.add_argument('--train_mat', type=str, default='data/raw/train_list.mat')
parser.add_argument('--val_mat', type=str, default='data/raw/test_list.mat')
parser.add_argument('--data_dir', type=str, default='data/processed/images')
parser.add_argument('--output', type=str, default='models/model.keras')
args = parser.parse_args()


# --- Fonction pour charger les chemins des fichiers Ã  partir des fichiers .mat ---
def load_file_list(mat_path):
    print(f"âš™ï¸ Chargement du fichier .mat depuis : {mat_path}")
    mat = loadmat(mat_path)
    return [item[0][0] for item in mat["file_list"]]

# --- Chargement des chemins d'images Ã  partir des fichiers .mat ---
print("ğŸ”„ Chargement des chemins d'images de l'entraÃ®nement et de la validation...")
train_list = load_file_list(args.train_mat)
val_list = load_file_list(args.val_mat)

# --- GÃ©nÃ©rateurs de donnÃ©es avec augmentation ---
print("ğŸ”„ Initialisation des gÃ©nÃ©rateurs de donnÃ©es avec augmentation...")
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20 if not args.custom_aug else 0,
    width_shift_range=0.2 if not args.custom_aug else 0,
    height_shift_range=0.2 if not args.custom_aug else 0,
    zoom_range=0.2 if not args.custom_aug else 0,
    horizontal_flip=True if not args.custom_aug else False,
    brightness_range=[0.8, 1.2] if not args.custom_aug else None,
    validation_split=0.2  # 20% pour la validation
    )

val_datagen = ImageDataGenerator(rescale=1./255)

# --- RÃ©cupÃ©rer les chemins absolus des images pour train et validation ---
def get_image_paths(file_list):
    return [os.path.join(args.data_dir, path) for path in file_list]

train_paths = get_image_paths(train_list)
val_paths = get_image_paths(val_list)

# --- FlowFromDirectory n'est pas utilisÃ© ici car les images sont dans un format .mat ---
# GÃ©nÃ©rateur pour l'entraÃ®nement
print("ğŸ”„ Initialisation du gÃ©nÃ©rateur d'entraÃ®nement...")
train_gen = train_datagen.flow_from_directory(
    directory=args.data_dir,
    target_size=(args.img_size, args.img_size),
    batch_size=args.batch_size,
    class_mode='categorical',
)
# Ce message est celui qui est affichÃ©
print(f"Nombre d'images et de classes trouvÃ©es pour l'entraÃ®nement : {train_gen.samples}, {train_gen.num_classes}")

# Imprime les classes dÃ©tectÃ©es dans les sous-dossiers
print(f"Classes dÃ©tectÃ©es : {train_gen.class_indices}")
# GÃ©nÃ©rateur pour la validation
print("ğŸ”„ Initialisation du gÃ©nÃ©rateur de validation...")
val_gen = val_datagen.flow_from_directory(
    directory=args.data_dir,
    target_size=(args.img_size, args.img_size),
    batch_size=args.batch_size,
    class_mode='categorical',
    shuffle=False,
)

# --- Choix du modÃ¨le ---
print(f"ğŸ§  Construction du modÃ¨le '{args.model}'...")
input_shape = (args.img_size, args.img_size, 3)
if args.model == 'scratch':
    model = build_cnn_scratch(train_gen.num_classes, val_gen.num_classes)
else:
    model = build_transfer_model(input_shape, train_gen.num_classes)

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# --- Checkpoint ---
os.makedirs(os.path.dirname(args.output), exist_ok=True)
checkpoint_cb = ModelCheckpoint(args.output, save_best_only=True, monitor='val_accuracy', mode='max')

# --- EntraÃ®nement ---
print(f"ğŸš€ DÃ©marrage de l'entraÃ®nement du modÃ¨le pour {args.epochs} epochs...")
model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=args.epochs,
    steps_per_epoch=train_gen.samples // 140,
    validation_steps=val_gen.samples // 140,
    callbacks=[checkpoint_cb]
)

print(f"âœ… ModÃ¨le sauvegardÃ© dans {args.output}")
